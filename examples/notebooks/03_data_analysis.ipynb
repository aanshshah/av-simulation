{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_title"
   },
   "source": [
    "# 📊 AV Simulation Data Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of autonomous vehicle simulation data, covering safety metrics, performance analysis, and behavioral insights.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/av-simulation/blob/main/examples/notebooks/03_data_analysis.ipynb)\n",
    "\n",
    "## 📋 What You'll Learn\n",
    "- Vehicle trajectory analysis and path planning insights\n",
    "- Safety metrics and collision risk assessment\n",
    "- Performance optimization opportunities\n",
    "- Autonomous decision pattern analysis\n",
    "- Statistical modeling and trend identification\n",
    "\n",
    "## 🔗 Prerequisites\n",
    "Complete data collection from: **[02_simulation_runner.ipynb](02_simulation_runner.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## 📦 Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Standard imports for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "    data_path = \"/content/\"\nexcept ImportError:\n",
    "    IN_COLAB = False\n",
    "    data_path = \"../\"\n",
    "\n",
    "print(\"📊 Data Analysis Environment Ready\")\n",
    "print(f\"🖥️  Running in: {'Google Colab' if IN_COLAB else 'Local Environment'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load simulation data\n",
    "def load_simulation_data(data_dir=\"exported_csv_data\"):\n",
    "    \"\"\"Load all simulation data files\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    files_to_load = {\n",
    "        'vehicles': 'all_vehicle_data.csv',\n",
    "        'environment': 'all_environment_data.csv',\n",
    "        'collisions': 'all_collision_events.csv',\n",
    "        'actions': 'all_action_events.csv'\n",
    "    }\n",
    "    \n",
    "    for key, filename in files_to_load.items():\n",
    "        filepath = f\"{data_path}{data_dir}/{filename}\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            data[key] = df\n",
    "            print(f\"✅ Loaded {key}: {len(df):,} records\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ File not found: {filepath}\")\n",
    "            data[key] = pd.DataFrame()  # Empty dataframe\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {key}: {e}\")\n",
    "            data[key] = pd.DataFrame()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "print(\"📁 Loading Simulation Data...\")\n",
    "sim_data = load_simulation_data()\n",
    "\n",
    "# Quick data overview\n",
    "if not sim_data['vehicles'].empty:\n",
    "    print(f\"\\n📈 Dataset Overview:\")\n",
    "    print(f\"Total simulation time: {sim_data['vehicles']['timestamp'].max():.1f} seconds\")\n",
    "    print(f\"Unique vehicles: {sim_data['vehicles']['vehicle_id'].nunique()}\")\n",
    "    print(f\"Simulation runs: {sim_data['vehicles']['run_id'].nunique()}\")\n",
    "    print(f\"Data points collected: {len(sim_data['vehicles']):,}\")\n",
    "else:\n",
    "    print(\"⚠️  No vehicle data found. Please run simulations first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep_header"
   },
   "source": [
    "## 🔧 Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_preparation"
   },
   "outputs": [],
   "source": [
    "def prepare_analysis_data(sim_data):\n",
    "    \"\"\"Prepare and engineer features for analysis\"\"\"\n",
    "    \n",
    "    if sim_data['vehicles'].empty:\n",
    "        print(\"No vehicle data available for analysis\")\n",
    "        return {}\n",
    "    \n",
    "    # Work with vehicle data\n",
    "    df = sim_data['vehicles'].copy()\n",
    "    \n",
    "    # Feature engineering\n",
    "    print(\"🔧 Engineering features...\")\n",
    "    \n",
    "    # Time-based features\n",
    "    df['time_bin'] = pd.cut(df['timestamp'], bins=20, labels=False)\n",
    "    \n",
    "    # Speed categories\n",
    "    df['speed_category'] = pd.cut(df['speed'], \n",
    "                                 bins=[0, 10, 20, 30, 50], \n",
    "                                 labels=['Slow', 'Medium', 'Fast', 'Very Fast'])\n",
    "    \n",
    "    # Distance traveled (approximate)\n",
    "    df = df.sort_values(['vehicle_id', 'timestamp'])\n",
    "    df['distance_delta'] = df.groupby('vehicle_id')['speed'].transform(\n",
    "        lambda x: x * 0.1  # Assuming 0.1s intervals\n",
    "    )\n",
    "    df['cumulative_distance'] = df.groupby('vehicle_id')['distance_delta'].cumsum()\n",
    "    \n",
    "    # Acceleration categories\n",
    "    df['accel_category'] = pd.cut(df['acceleration'], \n",
    "                                 bins=[-10, -2, -0.5, 0.5, 2, 10], \n",
    "                                 labels=['Hard Brake', 'Brake', 'Coast', 'Accelerate', 'Hard Accel'])\n",
    "    \n",
    "    # Lane change detection (simplified)\n",
    "    df['lane_change'] = df.groupby('vehicle_id')['lane_id'].diff().abs() > 0\n",
    "    \n",
    "    # Steering categories\n",
    "    df['steering_category'] = pd.cut(df['steering_angle'], \n",
    "                                   bins=[-1, -0.2, -0.05, 0.05, 0.2, 1], \n",
    "                                   labels=['Hard Left', 'Left', 'Straight', 'Right', 'Hard Right'])\n",
    "    \n",
    "    # Vehicle type flag\n",
    "    df['vehicle_type'] = df['is_ego'].map({True: 'Ego', False: 'Other'})\n",
    "    \n",
    "    print(f\"✅ Feature engineering complete. Dataset shape: {df.shape}\")\n",
    "    \n",
    "    # Separate ego and other vehicles\n",
    "    ego_df = df[df['is_ego'] == True].copy()\n",
    "    other_df = df[df['is_ego'] == False].copy()\n",
    "    \n",
    "    analysis_data = {\n",
    "        'all_vehicles': df,\n",
    "        'ego_vehicles': ego_df,\n",
    "        'other_vehicles': other_df,\n",
    "        'collisions': sim_data['collisions'],\n",
    "        'actions': sim_data['actions'],\n",
    "        'environment': sim_data['environment']\n",
    "    }\n",
    "    \n",
    "    return analysis_data\n",
    "\n",
    "# Prepare data for analysis\n",
    "analysis_data = prepare_analysis_data(sim_data)\n",
    "\n",
    "if analysis_data:\n",
    "    print(f\"\\n📊 Analysis Data Summary:\")\n",
    "    print(f\"All vehicles: {len(analysis_data['all_vehicles']):,} records\")\n",
    "    print(f\"Ego vehicles: {len(analysis_data['ego_vehicles']):,} records\")\n",
    "    print(f\"Other vehicles: {len(analysis_data['other_vehicles']):,} records\")\n",
    "    print(f\"Collision events: {len(analysis_data['collisions'])}\")\n",
    "    print(f\"Action events: {len(analysis_data['actions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_stats_header"
   },
   "source": [
    "## 📈 Basic Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_statistics"
   },
   "outputs": [],
   "source": [
    "def compute_basic_statistics(analysis_data):\n",
    "    \"\"\"Compute and display basic statistics\"\"\"\n",
    "    \n",
    "    if not analysis_data or analysis_data['all_vehicles'].empty:\n",
    "        print(\"No data available for statistical analysis\")\n",
    "        return\n",
    "    \n",
    "    df = analysis_data['all_vehicles']\n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    \n",
    "    print(\"📊 BASIC STATISTICS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n🚗 VEHICLE PERFORMANCE METRICS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    stats_summary = {\n",
    "        'Speed (m/s)': {\n",
    "            'Mean': df['speed'].mean(),\n",
    "            'Std': df['speed'].std(),\n",
    "            'Max': df['speed'].max(),\n",
    "            'Min': df['speed'].min()\n",
    "        },\n",
    "        'Acceleration (m/s²)': {\n",
    "            'Mean': df['acceleration'].mean(),\n",
    "            'Std': df['acceleration'].std(),\n",
    "            'Max': df['acceleration'].max(),\n",
    "            'Min': df['acceleration'].min()\n",
    "        },\n",
    "        'Steering (rad)': {\n",
    "            'Mean': df['steering_angle'].mean(),\n",
    "            'Std': df['steering_angle'].std(),\n",
    "            'Max': df['steering_angle'].max(),\n",
    "            'Min': df['steering_angle'].min()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for metric, values in stats_summary.items():\n",
    "        print(f\"\\n{metric}:\")\n",
    "        for stat, value in values.items():\n",
    "            print(f\"  {stat}: {value:.3f}\")\n",
    "    \n",
    "    # Ego vehicle specific stats\n",
    "    if not ego_df.empty:\n",
    "        print(\"\\n🎯 EGO VEHICLE ANALYSIS\")\n",
    "        print(\"-\" * 25)\n",
    "        print(f\"Total distance traveled: {ego_df['cumulative_distance'].max():.1f} m\")\n",
    "        print(f\"Average speed: {ego_df['speed'].mean():.1f} m/s\")\n",
    "        print(f\"Speed variance: {ego_df['speed'].var():.2f}\")\n",
    "        print(f\"Lane changes: {ego_df['lane_change'].sum()} times\")\n",
    "        \n",
    "        # Time in different speed categories\n",
    "        speed_dist = ego_df['speed_category'].value_counts(normalize=True) * 100\n",
    "        print(f\"\\nSpeed distribution:\")\n",
    "        for category, percentage in speed_dist.items():\n",
    "            print(f\"  {category}: {percentage:.1f}%\")\n",
    "    \n",
    "    # Safety metrics\n",
    "    print(\"\\n⚠️  SAFETY METRICS\")\n",
    "    print(\"-\" * 15)\n",
    "    \n",
    "    collision_df = analysis_data['collisions']\n",
    "    if not collision_df.empty:\n",
    "        print(f\"Total collisions: {len(collision_df)}\")\n",
    "        print(f\"Average collision speed: {collision_df['relative_speed'].mean():.1f} m/s\")\n",
    "        print(f\"Max collision speed: {collision_df['relative_speed'].max():.1f} m/s\")\n",
    "    else:\n",
    "        print(\"No collisions recorded ✅\")\n",
    "    \n",
    "    # Hard acceleration/braking events\n",
    "    hard_accel = len(df[df['acceleration'] > 3])\n",
    "    hard_brake = len(df[df['acceleration'] < -3])\n",
    "    print(f\"Hard acceleration events: {hard_accel}\")\n",
    "    print(f\"Hard braking events: {hard_brake}\")\n",
    "    \n",
    "    return stats_summary\n",
    "\n",
    "# Compute statistics\n",
    "basic_stats = compute_basic_statistics(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trajectory_analysis_header"
   },
   "source": [
    "## 🛣️ Trajectory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trajectory_analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_trajectories(analysis_data):\n",
    "    \"\"\"Analyze vehicle trajectories and movement patterns\"\"\"\n",
    "    \n",
    "    if not analysis_data or analysis_data['ego_vehicles'].empty:\n",
    "        print(\"No trajectory data available\")\n",
    "        return\n",
    "    \n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    other_df = analysis_data['other_vehicles']\n",
    "    \n",
    "    # Create trajectory analysis plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('🛣️ Vehicle Trajectory Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Position trajectory with speed coloring\n",
    "    if not ego_df.empty:\n",
    "        scatter = axes[0,0].scatter(ego_df['position_x'], ego_df['position_y'], \n",
    "                                  c=ego_df['speed'], cmap='viridis', \n",
    "                                  alpha=0.6, s=10)\n",
    "        axes[0,0].set_title('Ego Vehicle Trajectory\\n(colored by speed)')\n",
    "        axes[0,0].set_xlabel('Position X (m)')\n",
    "        axes[0,0].set_ylabel('Position Y (m)')\n",
    "        plt.colorbar(scatter, ax=axes[0,0], label='Speed (m/s)')\n",
    "    \n",
    "    # 2. Speed over time\n",
    "    if not ego_df.empty:\n",
    "        axes[0,1].plot(ego_df['timestamp'], ego_df['speed'], \n",
    "                      color='green', alpha=0.7, linewidth=1)\n",
    "        axes[0,1].set_title('Speed Profile Over Time')\n",
    "        axes[0,1].set_xlabel('Time (s)')\n",
    "        axes[0,1].set_ylabel('Speed (m/s)')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Acceleration over time\n",
    "    if not ego_df.empty:\n",
    "        axes[0,2].plot(ego_df['timestamp'], ego_df['acceleration'], \n",
    "                      color='red', alpha=0.7, linewidth=1)\n",
    "        axes[0,2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[0,2].set_title('Acceleration Profile')\n",
    "        axes[0,2].set_xlabel('Time (s)')\n",
    "        axes[0,2].set_ylabel('Acceleration (m/s²)')\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Steering angle over time\n",
    "    if not ego_df.empty:\n",
    "        axes[1,0].plot(ego_df['timestamp'], ego_df['steering_angle'], \n",
    "                      color='blue', alpha=0.7, linewidth=1)\n",
    "        axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[1,0].set_title('Steering Angle Profile')\n",
    "        axes[1,0].set_xlabel('Time (s)')\n",
    "        axes[1,0].set_ylabel('Steering Angle (rad)')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Vehicle interactions (if other vehicles present)\n",
    "    if not other_df.empty and not ego_df.empty:\n",
    "        # Sample some other vehicle data to avoid overcrowding\n",
    "        other_sample = other_df.sample(min(500, len(other_df)))\n",
    "        \n",
    "        axes[1,1].scatter(ego_df['position_x'], ego_df['position_y'], \n",
    "                         c='green', alpha=0.6, s=5, label='Ego Vehicle')\n",
    "        axes[1,1].scatter(other_sample['position_x'], other_sample['position_y'], \n",
    "                         c='blue', alpha=0.4, s=3, label='Other Vehicles')\n",
    "        axes[1,1].set_title('Vehicle Interactions')\n",
    "        axes[1,1].set_xlabel('Position X (m)')\n",
    "        axes[1,1].set_ylabel('Position Y (m)')\n",
    "        axes[1,1].legend()\n",
    "    \n",
    "    # 6. Cumulative distance\n",
    "    if not ego_df.empty:\n",
    "        axes[1,2].plot(ego_df['timestamp'], ego_df['cumulative_distance'], \n",
    "                      color='purple', alpha=0.8, linewidth=2)\n",
    "        axes[1,2].set_title('Cumulative Distance Traveled')\n",
    "        axes[1,2].set_xlabel('Time (s)')\n",
    "        axes[1,2].set_ylabel('Distance (m)')\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Trajectory statistics\n",
    "    if not ego_df.empty:\n",
    "        print(\"\\n📊 TRAJECTORY STATISTICS\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # Path efficiency (straight-line distance vs actual distance)\n",
    "        start_pos = (ego_df['position_x'].iloc[0], ego_df['position_y'].iloc[0])\n",
    "        end_pos = (ego_df['position_x'].iloc[-1], ego_df['position_y'].iloc[-1])\n",
    "        straight_distance = np.sqrt((end_pos[0] - start_pos[0])**2 + \n",
    "                                   (end_pos[1] - start_pos[1])**2)\n",
    "        actual_distance = ego_df['cumulative_distance'].max()\n",
    "        \n",
    "        if straight_distance > 0:\n",
    "            path_efficiency = straight_distance / actual_distance * 100\n",
    "            print(f\"Path efficiency: {path_efficiency:.1f}%\")\n",
    "        \n",
    "        print(f\"Total distance: {actual_distance:.1f} m\")\n",
    "        print(f\"Straight-line distance: {straight_distance:.1f} m\")\n",
    "        print(f\"Average speed: {ego_df['speed'].mean():.1f} m/s\")\n",
    "        print(f\"Speed standard deviation: {ego_df['speed'].std():.2f} m/s\")\n",
    "        print(f\"Max acceleration: {ego_df['acceleration'].max():.2f} m/s²\")\n",
    "        print(f\"Max deceleration: {ego_df['acceleration'].min():.2f} m/s²\")\n",
    "\n",
    "# Run trajectory analysis\n",
    "analyze_trajectories(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "safety_analysis_header"
   },
   "source": [
    "## ⚠️ Safety and Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "safety_analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_safety_metrics(analysis_data):\n",
    "    \"\"\"Comprehensive safety and risk analysis\"\"\"\n",
    "    \n",
    "    if not analysis_data:\n",
    "        print(\"No data available for safety analysis\")\n",
    "        return\n",
    "    \n",
    "    df = analysis_data['all_vehicles']\n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    collision_df = analysis_data['collisions']\n",
    "    \n",
    "    print(\"⚠️  SAFETY AND RISK ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create safety analysis plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('⚠️ Safety and Risk Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Speed distribution and safety zones\n",
    "    if not df.empty:\n",
    "        axes[0,0].hist(df['speed'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0,0].axvline(x=25, color='orange', linestyle='--', label='Speed Limit')\n",
    "        axes[0,0].axvline(x=30, color='red', linestyle='--', label='Danger Zone')\n",
    "        axes[0,0].set_title('Speed Distribution\\nwith Safety Zones')\n",
    "        axes[0,0].set_xlabel('Speed (m/s)')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Acceleration distribution (aggressive driving detection)\n",
    "    if not df.empty:\n",
    "        axes[0,1].hist(df['acceleration'], bins=30, alpha=0.7, color='lightcoral')\n",
    "        axes[0,1].axvline(x=3, color='red', linestyle='--', label='Hard Acceleration')\n",
    "        axes[0,1].axvline(x=-3, color='red', linestyle='--', label='Hard Braking')\n",
    "        axes[0,1].set_title('Acceleration Distribution\\n(Aggressive Driving Detection)')\n",
    "        axes[0,1].set_xlabel('Acceleration (m/s²)')\n",
    "        axes[0,1].set_ylabel('Frequency')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Risk heatmap (speed vs acceleration)\n",
    "    if not ego_df.empty:\n",
    "        # Create risk score based on speed and acceleration\n",
    "        risk_data = ego_df[['speed', 'acceleration']].copy()\n",
    "        \n",
    "        # Bin the data for heatmap\n",
    "        speed_bins = np.linspace(risk_data['speed'].min(), risk_data['speed'].max(), 10)\n",
    "        accel_bins = np.linspace(risk_data['acceleration'].min(), risk_data['acceleration'].max(), 10)\n",
    "        \n",
    "        hist, xedges, yedges = np.histogram2d(risk_data['speed'], risk_data['acceleration'], \n",
    "                                             bins=[speed_bins, accel_bins])\n",
    "        \n",
    "        im = axes[0,2].imshow(hist.T, origin='lower', cmap='Reds', alpha=0.7)\n",
    "        axes[0,2].set_title('Risk Heatmap\\n(Speed vs Acceleration)')\n",
    "        axes[0,2].set_xlabel('Speed (binned)')\n",
    "        axes[0,2].set_ylabel('Acceleration (binned)')\n",
    "        plt.colorbar(im, ax=axes[0,2], label='Frequency')\n",
    "    \n",
    "    # 4. Safety events timeline\n",
    "    if not ego_df.empty:\n",
    "        # Identify safety events\n",
    "        safety_events = ego_df[\n",
    "            (ego_df['speed'] > 30) |  # High speed\n",
    "            (ego_df['acceleration'] > 3) |  # Hard acceleration\n",
    "            (ego_df['acceleration'] < -3) |  # Hard braking\n",
    "            (abs(ego_df['steering_angle']) > 0.5)  # Sharp turns\n",
    "        ]\n",
    "        \n",
    "        if not safety_events.empty:\n",
    "            axes[1,0].scatter(safety_events['timestamp'], safety_events['speed'], \n",
    "                            c='red', alpha=0.6, s=20, label='Safety Events')\n",
    "            axes[1,0].plot(ego_df['timestamp'], ego_df['speed'], \n",
    "                          color='blue', alpha=0.3, linewidth=1)\n",
    "            axes[1,0].set_title('Safety Events Timeline')\n",
    "            axes[1,0].set_xlabel('Time (s)')\n",
    "            axes[1,0].set_ylabel('Speed (m/s)')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Collision analysis (if any)\n",
    "    if not collision_df.empty:\n",
    "        axes[1,1].scatter(collision_df['collision_point_x'], collision_df['collision_point_y'], \n",
    "                         c=collision_df['relative_speed'], cmap='Reds', \n",
    "                         s=100, alpha=0.8, edgecolor='black')\n",
    "        axes[1,1].set_title('Collision Locations\\n(sized by impact speed)')\n",
    "        axes[1,1].set_xlabel('X Position (m)')\n",
    "        axes[1,1].set_ylabel('Y Position (m)')\n",
    "        \n",
    "        # Add collision times as text\n",
    "        for _, collision in collision_df.iterrows():\n",
    "            axes[1,1].annotate(f't={collision[\"timestamp\"]:.1f}s', \n",
    "                              (collision['collision_point_x'], collision['collision_point_y']),\n",
    "                              xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'No Collisions\\nDetected ✅', \n",
    "                      transform=axes[1,1].transAxes, \n",
    "                      ha='center', va='center', fontsize=14, \n",
    "                      bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "        axes[1,1].set_title('Collision Analysis')\n",
    "    \n",
    "    # 6. Safety score over time\n",
    "    if not ego_df.empty:\n",
    "        # Calculate safety score (0-100, higher is safer)\n",
    "        safety_score = 100 - (\n",
    "            (ego_df['speed'] / 40 * 30) +  # Speed factor (max 30 points)\n",
    "            (abs(ego_df['acceleration']) / 5 * 25) +  # Acceleration factor (max 25 points)\n",
    "            (abs(ego_df['steering_angle']) / 0.785 * 20) +  # Steering factor (max 20 points)\n",
    "            (ego_df['lane_change'].astype(int) * 25)  # Lane change penalty (25 points)\n",
    "        ).clip(0, 100)\n",
    "        \n",
    "        axes[1,2].plot(ego_df['timestamp'], safety_score, color='green', linewidth=2)\n",
    "        axes[1,2].fill_between(ego_df['timestamp'], safety_score, alpha=0.3, color='green')\n",
    "        axes[1,2].axhline(y=70, color='orange', linestyle='--', label='Caution Threshold')\n",
    "        axes[1,2].axhline(y=50, color='red', linestyle='--', label='Danger Threshold')\n",
    "        axes[1,2].set_title('Safety Score Over Time')\n",
    "        axes[1,2].set_xlabel('Time (s)')\n",
    "        axes[1,2].set_ylabel('Safety Score (0-100)')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "        axes[1,2].set_ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Safety statistics\n",
    "    print(\"\\n📊 SAFETY STATISTICS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    if not df.empty:\n",
    "        # Speed violations\n",
    "        speed_violations = len(df[df['speed'] > 30])\n",
    "        total_records = len(df)\n",
    "        speed_violation_rate = speed_violations / total_records * 100\n",
    "        \n",
    "        print(f\"Speed violations (>30 m/s): {speed_violations} ({speed_violation_rate:.1f}%)\")\n",
    "        \n",
    "        # Aggressive driving events\n",
    "        hard_accel_events = len(df[df['acceleration'] > 3])\n",
    "        hard_brake_events = len(df[df['acceleration'] < -3])\n",
    "        \n",
    "        print(f\"Hard acceleration events: {hard_accel_events}\")\n",
    "        print(f\"Hard braking events: {hard_brake_events}\")\n",
    "        \n",
    "        # Collision statistics\n",
    "        if not collision_df.empty:\n",
    "            print(f\"\\nCollision Statistics:\")\n",
    "            print(f\"Total collisions: {len(collision_df)}\")\n",
    "            print(f\"Average impact speed: {collision_df['relative_speed'].mean():.1f} m/s\")\n",
    "            print(f\"Severity distribution:\")\n",
    "            \n",
    "            # Classify collision severity\n",
    "            severity = pd.cut(collision_df['relative_speed'], \n",
    "                            bins=[0, 5, 15, 30, 100], \n",
    "                            labels=['Minor', 'Moderate', 'Severe', 'Fatal'])\n",
    "            severity_counts = severity.value_counts()\n",
    "            for sev, count in severity_counts.items():\n",
    "                print(f\"  {sev}: {count} ({count/len(collision_df)*100:.1f}%)\")\n",
    "        \n",
    "        # Overall safety rating\n",
    "        if not ego_df.empty:\n",
    "            avg_safety_score = safety_score.mean()\n",
    "            print(f\"\\nOverall Safety Rating: {avg_safety_score:.1f}/100\")\n",
    "            \n",
    "            if avg_safety_score >= 80:\n",
    "                rating = \"Excellent ⭐⭐⭐⭐⭐\"\n",
    "            elif avg_safety_score >= 70:\n",
    "                rating = \"Good ⭐⭐⭐⭐\"\n",
    "            elif avg_safety_score >= 60:\n",
    "                rating = \"Fair ⭐⭐⭐\"\n",
    "            elif avg_safety_score >= 50:\n",
    "                rating = \"Poor ⭐⭐\"\n",
    "            else:\n",
    "                rating = \"Dangerous ⭐\"\n",
    "            \n",
    "            print(f\"Safety Grade: {rating}\")\n",
    "\n",
    "# Run safety analysis\n",
    "analyze_safety_metrics(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "behavior_analysis_header"
   },
   "source": [
    "## 🧠 Autonomous Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "behavior_analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_autonomous_behavior(analysis_data):\n",
    "    \"\"\"Analyze autonomous vehicle decision-making patterns\"\"\"\n",
    "    \n",
    "    if not analysis_data:\n",
    "        print(\"No data available for behavior analysis\")\n",
    "        return\n",
    "    \n",
    "    actions_df = analysis_data['actions']\n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    \n",
    "    print(\"🧠 AUTONOMOUS BEHAVIOR ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if actions_df.empty:\n",
    "        print(\"No action data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create behavior analysis plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('🧠 Autonomous Decision-Making Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Action frequency distribution\n",
    "    action_counts = actions_df['action'].value_counts()\n",
    "    axes[0,0].pie(action_counts.values, labels=action_counts.index, autopct='%1.1f%%')\n",
    "    axes[0,0].set_title('Action Distribution')\n",
    "    \n",
    "    # 2. Action transitions\n",
    "    if 'previous_action' in actions_df.columns:\n",
    "        transition_matrix = pd.crosstab(actions_df['previous_action'], actions_df['action'])\n",
    "        \n",
    "        if not transition_matrix.empty:\n",
    "            sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0,1])\n",
    "            axes[0,1].set_title('Action Transition Matrix')\n",
    "            axes[0,1].set_xlabel('Next Action')\n",
    "            axes[0,1].set_ylabel('Previous Action')\n",
    "    \n",
    "    # 3. Decision timing analysis\n",
    "    action_intervals = actions_df['timestamp'].diff().dropna()\n",
    "    axes[0,2].hist(action_intervals, bins=20, alpha=0.7, color='lightblue')\n",
    "    axes[0,2].set_title('Decision Intervals')\n",
    "    axes[0,2].set_xlabel('Time Between Decisions (s)')\n",
    "    axes[0,2].set_ylabel('Frequency')\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Reason for actions\n",
    "    if 'reason' in actions_df.columns:\n",
    "        reason_counts = actions_df['reason'].value_counts()\n",
    "        axes[1,0].barh(range(len(reason_counts)), reason_counts.values)\n",
    "        axes[1,0].set_yticks(range(len(reason_counts)))\n",
    "        axes[1,0].set_yticklabels(reason_counts.index)\n",
    "        axes[1,0].set_title('Decision Reasoning')\n",
    "        axes[1,0].set_xlabel('Frequency')\n",
    "    \n",
    "    # 5. Actions over time\n",
    "    axes[1,1].scatter(actions_df['timestamp'], actions_df['action'], alpha=0.6)\n",
    "    axes[1,1].set_title('Actions Timeline')\n",
    "    axes[1,1].set_xlabel('Time (s)')\n",
    "    axes[1,1].set_ylabel('Action Type')\n",
    "    axes[1,1].tick_params(axis='y', rotation=45)\n",
    "    \n",
    "    # 6. Performance correlation\n",
    "    if not ego_df.empty:\n",
    "        # Correlate actions with speed changes\n",
    "        action_times = actions_df['timestamp'].values\n",
    "        \n",
    "        # Find speed around action times\n",
    "        speed_changes = []\n",
    "        for action_time in action_times:\n",
    "            # Get speed before and after action\n",
    "            before = ego_df[ego_df['timestamp'] <= action_time]['speed'].iloc[-1:]\n",
    "            after = ego_df[ego_df['timestamp'] > action_time]['speed'].iloc[:1]\n",
    "            \n",
    "            if len(before) > 0 and len(after) > 0:\n",
    "                speed_change = after.iloc[0] - before.iloc[0]\n",
    "                speed_changes.append(speed_change)\n",
    "            else:\n",
    "                speed_changes.append(0)\n",
    "        \n",
    "        if speed_changes:\n",
    "            axes[1,2].bar(range(len(actions_df)), speed_changes, \n",
    "                         color=['green' if x > 0 else 'red' for x in speed_changes])\n",
    "            axes[1,2].set_title('Speed Change After Actions')\n",
    "            axes[1,2].set_xlabel('Action Index')\n",
    "            axes[1,2].set_ylabel('Speed Change (m/s)')\n",
    "            axes[1,2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "            axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Behavior statistics\n",
    "    print(\"\\n📊 BEHAVIOR STATISTICS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    print(f\"Total decisions made: {len(actions_df)}\")\n",
    "    print(f\"Average decision interval: {action_intervals.mean():.2f}s\")\n",
    "    print(f\"Decision frequency: {1/action_intervals.mean():.2f} decisions/second\")\n",
    "    \n",
    "    print(f\"\\nAction breakdown:\")\n",
    "    for action, count in action_counts.items():\n",
    "        percentage = count / len(actions_df) * 100\n",
    "        print(f\"  {action}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Decision consistency analysis\n",
    "    if 'previous_action' in actions_df.columns:\n",
    "        # Count repeated actions (consistency indicator)\n",
    "        repeated_actions = sum(actions_df['action'] == actions_df['previous_action'])\n",
    "        consistency_rate = repeated_actions / len(actions_df) * 100\n",
    "        print(f\"\\nDecision consistency: {consistency_rate:.1f}%\")\n",
    "        \n",
    "        # Most common transitions\n",
    "        transitions = actions_df.groupby(['previous_action', 'action']).size().sort_values(ascending=False)\n",
    "        print(f\"\\nTop 3 action transitions:\")\n",
    "        for i, ((prev, curr), count) in enumerate(transitions.head(3).items()):\n",
    "            print(f\"  {i+1}. {prev} → {curr}: {count} times\")\n",
    "\n",
    "# Run behavior analysis\n",
    "analyze_autonomous_behavior(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance_header"
   },
   "source": [
    "## 🏎️ Performance Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance_analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_performance_optimization(analysis_data):\n",
    "    \"\"\"Analyze performance metrics and optimization opportunities\"\"\"\n",
    "    \n",
    "    if not analysis_data or analysis_data['ego_vehicles'].empty:\n",
    "        print(\"No data available for performance analysis\")\n",
    "        return\n",
    "    \n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    \n",
    "    print(\"🏎️ PERFORMANCE OPTIMIZATION ANALYSIS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Create performance analysis plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('🏎️ Performance Optimization Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Efficiency over time (speed consistency)\n",
    "    # Calculate rolling efficiency (inverse of speed variance)\n",
    "    window_size = min(50, len(ego_df) // 10)\n",
    "    if window_size > 1:\n",
    "        rolling_speed_std = ego_df['speed'].rolling(window=window_size).std()\n",
    "        efficiency = 1 / (rolling_speed_std + 0.1)  # Add small constant to avoid division by zero\n",
    "        \n",
    "        axes[0,0].plot(ego_df['timestamp'], efficiency, color='blue', linewidth=2)\n",
    "        axes[0,0].set_title('Speed Consistency (Efficiency)\\nHigher = More Consistent')\n",
    "        axes[0,0].set_xlabel('Time (s)')\n",
    "        axes[0,0].set_ylabel('Efficiency Score')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Energy consumption estimation (based on acceleration)\n",
    "    # Simplified energy model: E ∝ mass × acceleration² × time\n",
    "    energy_consumption = abs(ego_df['acceleration']) ** 2 * 0.1  # Simplified model\n",
    "    cumulative_energy = energy_consumption.cumsum()\n",
    "    \n",
    "    axes[0,1].plot(ego_df['timestamp'], cumulative_energy, color='red', linewidth=2)\n",
    "    axes[0,1].set_title('Estimated Energy Consumption')\n",
    "    axes[0,1].set_xlabel('Time (s)')\n",
    "    axes[0,1].set_ylabel('Energy (arbitrary units)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Speed vs target speed (if we assume target is 25 m/s)\n",
    "    target_speed = 25.0\n",
    "    speed_error = ego_df['speed'] - target_speed\n",
    "    \n",
    "    axes[0,2].plot(ego_df['timestamp'], ego_df['speed'], \n",
    "                  label='Actual Speed', color='blue', alpha=0.7)\n",
    "    axes[0,2].axhline(y=target_speed, color='green', linestyle='--', \n",
    "                     label=f'Target Speed ({target_speed} m/s)')\n",
    "    axes[0,2].fill_between(ego_df['timestamp'], ego_df['speed'], target_speed, \n",
    "                          alpha=0.3, color='red' if speed_error.mean() > 0 else 'blue')\n",
    "    axes[0,2].set_title('Speed Tracking Performance')\n",
    "    axes[0,2].set_xlabel('Time (s)')\n",
    "    axes[0,2].set_ylabel('Speed (m/s)')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Smoothness analysis (jerk = rate of change of acceleration)\n",
    "    jerk = ego_df['acceleration'].diff() / 0.1  # Assuming 0.1s intervals\n",
    "    \n",
    "    axes[1,0].plot(ego_df['timestamp'][1:], jerk[1:], color='purple', alpha=0.7)\n",
    "    axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1,0].set_title('Jerk (Smoothness)\\nLower = Smoother')\n",
    "    axes[1,0].set_xlabel('Time (s)')\n",
    "    axes[1,0].set_ylabel('Jerk (m/s³)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Optimization opportunities heatmap\n",
    "    # Create bins for speed and acceleration to identify problematic combinations\n",
    "    speed_bins = np.linspace(ego_df['speed'].min(), ego_df['speed'].max(), 8)\n",
    "    accel_bins = np.linspace(ego_df['acceleration'].min(), ego_df['acceleration'].max(), 8)\n",
    "    \n",
    "    # Calculate \"inefficiency\" as deviation from ideal (constant speed, zero acceleration)\n",
    "    inefficiency = abs(speed_error) + abs(ego_df['acceleration']) * 5\n",
    "    \n",
    "    # Create 2D histogram weighted by inefficiency\n",
    "    hist, xedges, yedges = np.histogram2d(ego_df['speed'], ego_df['acceleration'], \n",
    "                                         bins=[speed_bins, accel_bins], weights=inefficiency)\n",
    "    \n",
    "    im = axes[1,1].imshow(hist.T, origin='lower', cmap='Reds', alpha=0.8)\n",
    "    axes[1,1].set_title('Inefficiency Heatmap\\n(Red = Needs Optimization)')\n",
    "    axes[1,1].set_xlabel('Speed (binned)')\n",
    "    axes[1,1].set_ylabel('Acceleration (binned)')\n",
    "    plt.colorbar(im, ax=axes[1,1], label='Inefficiency Score')\n",
    "    \n",
    "    # 6. Performance metrics over time\n",
    "    # Combine multiple metrics into a performance score\n",
    "    speed_score = 100 - abs(speed_error) * 2  # Penalty for speed deviation\n",
    "    smoothness_score = 100 - abs(jerk[1:]) * 10  # Penalty for jerkiness\n",
    "    energy_score = 100 - energy_consumption * 100  # Penalty for energy use\n",
    "    \n",
    "    # Align arrays (jerk is one element shorter)\n",
    "    min_len = min(len(speed_score), len(smoothness_score), len(energy_score))\n",
    "    performance_score = (\n",
    "        speed_score[:min_len] + \n",
    "        smoothness_score[:min_len] + \n",
    "        energy_score[:min_len]\n",
    "    ) / 3\n",
    "    \n",
    "    axes[1,2].plot(ego_df['timestamp'][:min_len], performance_score, \n",
    "                  color='green', linewidth=2, label='Overall Performance')\n",
    "    axes[1,2].plot(ego_df['timestamp'][:min_len], speed_score[:min_len], \n",
    "                  alpha=0.5, label='Speed Score')\n",
    "    axes[1,2].plot(ego_df['timestamp'][1:min_len+1], smoothness_score[:min_len], \n",
    "                  alpha=0.5, label='Smoothness Score')\n",
    "    axes[1,2].plot(ego_df['timestamp'][:min_len], energy_score[:min_len], \n",
    "                  alpha=0.5, label='Energy Score')\n",
    "    \n",
    "    axes[1,2].set_title('Performance Metrics')\n",
    "    axes[1,2].set_xlabel('Time (s)')\n",
    "    axes[1,2].set_ylabel('Score (0-100)')\n",
    "    axes[1,2].legend()\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    axes[1,2].set_ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance statistics and recommendations\n",
    "    print(\"\\n📊 PERFORMANCE METRICS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    avg_speed_error = abs(speed_error).mean()\n",
    "    max_speed_error = abs(speed_error).max()\n",
    "    avg_jerk = abs(jerk).mean()\n",
    "    max_jerk = abs(jerk).max()\n",
    "    total_energy = cumulative_energy.iloc[-1]\n",
    "    \n",
    "    print(f\"Speed tracking:\")\n",
    "    print(f\"  Average error: {avg_speed_error:.2f} m/s\")\n",
    "    print(f\"  Maximum error: {max_speed_error:.2f} m/s\")\n",
    "    print(f\"  RMS error: {np.sqrt((speed_error**2).mean()):.2f} m/s\")\n",
    "    \n",
    "    print(f\"\\nSmoothness:\")\n",
    "    print(f\"  Average jerk: {avg_jerk:.2f} m/s³\")\n",
    "    print(f\"  Maximum jerk: {max_jerk:.2f} m/s³\")\n",
    "    print(f\"  Jerk variance: {jerk.var():.2f}\")\n",
    "    \n",
    "    print(f\"\\nEnergy efficiency:\")\n",
    "    print(f\"  Total energy: {total_energy:.2f} units\")\n",
    "    print(f\"  Energy per distance: {total_energy/ego_df['cumulative_distance'].max():.3f} units/m\")\n",
    "    \n",
    "    print(f\"\\nOverall performance score: {performance_score.mean():.1f}/100\")\n",
    "    \n",
    "    # Optimization recommendations\n",
    "    print(\"\\n💡 OPTIMIZATION RECOMMENDATIONS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    if avg_speed_error > 2:\n",
    "        print(\"🎯 Speed Control: Improve speed tracking accuracy\")\n",
    "        print(\"   - Consider tuning PID controller parameters\")\n",
    "        print(\"   - Implement predictive speed control\")\n",
    "    \n",
    "    if avg_jerk > 2:\n",
    "        print(\"🌊 Smoothness: Reduce jerkiness in control\")\n",
    "        print(\"   - Implement smoother acceleration profiles\")\n",
    "        print(\"   - Add jerk minimization to cost function\")\n",
    "    \n",
    "    if total_energy > 50:  # Arbitrary threshold\n",
    "        print(\"⚡ Energy: Optimize for energy efficiency\")\n",
    "        print(\"   - Reduce unnecessary acceleration/deceleration\")\n",
    "        print(\"   - Implement eco-driving strategies\")\n",
    "    \n",
    "    # Identify worst performing time periods\n",
    "    worst_performance_idx = performance_score.argmin()\n",
    "    worst_time = ego_df['timestamp'].iloc[worst_performance_idx]\n",
    "    print(f\"\\n⚠️  Worst performance at t={worst_time:.1f}s\")\n",
    "    print(f\"   Performance score: {performance_score.iloc[worst_performance_idx]:.1f}/100\")\n",
    "    \n",
    "    return {\n",
    "        'avg_speed_error': avg_speed_error,\n",
    "        'avg_jerk': avg_jerk,\n",
    "        'total_energy': total_energy,\n",
    "        'performance_score': performance_score.mean()\n",
    "    }\n",
    "\n",
    "# Run performance analysis\n",
    "performance_metrics = analyze_performance_optimization(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml_analysis_header"
   },
   "source": [
    "## 🤖 Machine Learning Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_analysis"
   },
   "outputs": [],
   "source": [
    "def ml_behavior_clustering(analysis_data):\n",
    "    \"\"\"Apply machine learning to identify behavioral patterns\"\"\"\n",
    "    \n",
    "    if not analysis_data or analysis_data['ego_vehicles'].empty:\n",
    "        print(\"No data available for ML analysis\")\n",
    "        return\n",
    "    \n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    \n",
    "    print(\"🤖 MACHINE LEARNING BEHAVIORAL ANALYSIS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Prepare features for clustering\n",
    "    features = ['speed', 'acceleration', 'steering_angle', 'heading']\n",
    "    \n",
    "    # Check if all features are available\n",
    "    available_features = [f for f in features if f in ego_df.columns]\n",
    "    \n",
    "    if len(available_features) < 2:\n",
    "        print(\"Insufficient features for ML analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = ego_df[available_features].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Determine optimal number of clusters using elbow method\n",
    "    k_range = range(2, min(8, len(X) // 10 + 1))\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_scaled)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "    \n",
    "    # Find optimal k (highest silhouette score)\n",
    "    optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "    \n",
    "    # Apply clustering with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add clusters to dataframe\n",
    "    ego_df_ml = ego_df.copy()\n",
    "    ego_df_ml['cluster'] = clusters\n",
    "    \n",
    "    # Create ML analysis plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('🤖 Machine Learning Behavioral Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Elbow curve\n",
    "    axes[0,0].plot(k_range, inertias, 'bo-', label='Inertia')\n",
    "    axes[0,0].axvline(x=optimal_k, color='red', linestyle='--', \n",
    "                     label=f'Optimal k={optimal_k}')\n",
    "    axes[0,0].set_title('Elbow Method for Optimal k')\n",
    "    axes[0,0].set_xlabel('Number of Clusters (k)')\n",
    "    axes[0,0].set_ylabel('Inertia')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Silhouette scores\n",
    "    axes[0,1].plot(k_range, silhouette_scores, 'go-')\n",
    "    axes[0,1].axvline(x=optimal_k, color='red', linestyle='--', \n",
    "                     label=f'Optimal k={optimal_k}')\n",
    "    axes[0,1].set_title('Silhouette Score Analysis')\n",
    "    axes[0,1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[0,1].set_ylabel('Silhouette Score')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Cluster visualization (speed vs acceleration)\n",
    "    scatter = axes[0,2].scatter(ego_df_ml['speed'], ego_df_ml['acceleration'], \n",
    "                               c=clusters, cmap='viridis', alpha=0.6)\n",
    "    axes[0,2].set_title('Behavioral Clusters\\n(Speed vs Acceleration)')\n",
    "    axes[0,2].set_xlabel('Speed (m/s)')\n",
    "    axes[0,2].set_ylabel('Acceleration (m/s²)')\n",
    "    plt.colorbar(scatter, ax=axes[0,2], label='Cluster')\n",
    "    \n",
    "    # 4. Cluster timeline\n",
    "    axes[1,0].scatter(ego_df_ml['timestamp'], clusters, \n",
    "                     c=clusters, cmap='viridis', alpha=0.7)\n",
    "    axes[1,0].set_title('Behavioral Clusters Over Time')\n",
    "    axes[1,0].set_xlabel('Time (s)')\n",
    "    axes[1,0].set_ylabel('Cluster')\n",
    "    \n",
    "    # 5. Cluster characteristics (violin plot)\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'Speed': ego_df_ml['speed'],\n",
    "        'Cluster': clusters\n",
    "    })\n",
    "    \n",
    "    for cluster_id in sorted(cluster_df['Cluster'].unique()):\n",
    "        cluster_data = cluster_df[cluster_df['Cluster'] == cluster_id]['Speed']\n",
    "        axes[1,1].hist(cluster_data, alpha=0.6, label=f'Cluster {cluster_id}', bins=15)\n",
    "    \n",
    "    axes[1,1].set_title('Speed Distribution by Cluster')\n",
    "    axes[1,1].set_xlabel('Speed (m/s)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Feature importance (cluster centers)\n",
    "    cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    center_df = pd.DataFrame(cluster_centers, columns=available_features)\n",
    "    \n",
    "    # Heatmap of cluster centers\n",
    "    sns.heatmap(center_df.T, annot=True, fmt='.2f', cmap='RdYlBu_r', \n",
    "                ax=axes[1,2], cbar_kws={'label': 'Feature Value'})\n",
    "    axes[1,2].set_title('Cluster Centers\\n(Behavioral Signatures)')\n",
    "    axes[1,2].set_xlabel('Cluster')\n",
    "    axes[1,2].set_ylabel('Features')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze cluster characteristics\n",
    "    print(f\"\\n📊 CLUSTER ANALYSIS (k={optimal_k})\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for cluster_id in sorted(np.unique(clusters)):\n",
    "        cluster_data = ego_df_ml[ego_df_ml['cluster'] == cluster_id]\n",
    "        cluster_size = len(cluster_data)\n",
    "        cluster_duration = cluster_data['timestamp'].max() - cluster_data['timestamp'].min()\n",
    "        \n",
    "        print(f\"\\nCluster {cluster_id}:\")\n",
    "        print(f\"  Size: {cluster_size} points ({cluster_size/len(ego_df_ml)*100:.1f}%)\")\n",
    "        print(f\"  Duration: {cluster_duration:.1f}s\")\n",
    "        print(f\"  Avg Speed: {cluster_data['speed'].mean():.1f} m/s\")\n",
    "        print(f\"  Avg Acceleration: {cluster_data['acceleration'].mean():.2f} m/s²\")\n",
    "        \n",
    "        # Characterize behavior\n",
    "        avg_speed = cluster_data['speed'].mean()\n",
    "        avg_accel = cluster_data['acceleration'].mean()\n",
    "        \n",
    "        if avg_speed > 25 and avg_accel > 1:\n",
    "            behavior = \"Aggressive (High speed, accelerating)\"\n",
    "        elif avg_speed < 15 and avg_accel < -1:\n",
    "            behavior = \"Cautious (Low speed, decelerating)\"\n",
    "        elif abs(avg_accel) < 0.5:\n",
    "            behavior = \"Steady (Constant speed)\"\n",
    "        elif avg_accel > 1:\n",
    "            behavior = \"Accelerating\"\n",
    "        elif avg_accel < -1:\n",
    "            behavior = \"Decelerating\"\n",
    "        else:\n",
    "            behavior = \"Mixed\"\n",
    "        \n",
    "        print(f\"  Behavior: {behavior}\")\n",
    "    \n",
    "    # Behavioral insights\n",
    "    print(f\"\\n💡 BEHAVIORAL INSIGHTS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    dominant_cluster = pd.Series(clusters).value_counts().index[0]\n",
    "    dominant_percentage = pd.Series(clusters).value_counts().iloc[0] / len(clusters) * 100\n",
    "    \n",
    "    print(f\"Dominant behavior: Cluster {dominant_cluster} ({dominant_percentage:.1f}% of time)\")\n",
    "    print(f\"Behavioral diversity: {optimal_k} distinct patterns identified\")\n",
    "    print(f\"Silhouette score: {max(silhouette_scores):.3f} (higher = better separation)\")\n",
    "    \n",
    "    # Transition analysis\n",
    "    transitions = []\n",
    "    for i in range(1, len(clusters)):\n",
    "        if clusters[i] != clusters[i-1]:\n",
    "            transitions.append((clusters[i-1], clusters[i]))\n",
    "    \n",
    "    if transitions:\n",
    "        transition_counts = pd.Series(transitions).value_counts()\n",
    "        print(f\"\\nBehavioral transitions: {len(transitions)} changes\")\n",
    "        print(f\"Most common transition: {transition_counts.index[0]} ({transition_counts.iloc[0]} times)\")\n",
    "    \n",
    "    return {\n",
    "        'clusters': clusters,\n",
    "        'optimal_k': optimal_k,\n",
    "        'silhouette_score': max(silhouette_scores),\n",
    "        'cluster_centers': center_df\n",
    "    }\n",
    "\n",
    "# Run ML analysis\n",
    "ml_results = ml_behavior_clustering(analysis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_header"
   },
   "source": [
    "## 📋 Analysis Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analysis_summary"
   },
   "outputs": [],
   "source": [
    "def generate_analysis_summary(analysis_data, performance_metrics, ml_results):\n",
    "    \"\"\"Generate comprehensive analysis summary\"\"\"\n",
    "    \n",
    "    print(\"📋 COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not analysis_data or analysis_data['ego_vehicles'].empty:\n",
    "        print(\"No data available for summary\")\n",
    "        return\n",
    "    \n",
    "    ego_df = analysis_data['ego_vehicles']\n",
    "    collision_df = analysis_data['collisions']\n",
    "    \n",
    "    # Data overview\n",
    "    print(f\"\\n📊 DATA OVERVIEW\")\n",
    "    print(f\"-\" * 15)\n",
    "    print(f\"Total simulation time: {ego_df['timestamp'].max():.1f} seconds\")\n",
    "    print(f\"Data points collected: {len(ego_df):,}\")\n",
    "    print(f\"Sampling rate: {len(ego_df)/ego_df['timestamp'].max():.1f} Hz\")\n",
    "    print(f\"Total distance: {ego_df['cumulative_distance'].max():.1f} meters\")\n",
    "    \n",
    "    # Safety summary\n",
    "    print(f\"\\n⚠️  SAFETY ASSESSMENT\")\n",
    "    print(f\"-\" * 20)\n",
    "    \n",
    "    if not collision_df.empty:\n",
    "        print(f\"🔴 Collisions detected: {len(collision_df)}\")\n",
    "        print(f\"   Average impact speed: {collision_df['relative_speed'].mean():.1f} m/s\")\n",
    "        safety_rating = \"UNSAFE\"\n",
    "    else:\n",
    "        print(f\"✅ No collisions detected\")\n",
    "        safety_rating = \"SAFE\"\n",
    "    \n",
    "    # Speed violations\n",
    "    speed_violations = len(ego_df[ego_df['speed'] > 30])\n",
    "    if speed_violations > 0:\n",
    "        print(f\"⚠️  Speed violations: {speed_violations} instances\")\n",
    "    else:\n",
    "        print(f\"✅ No speed violations\")\n",
    "    \n",
    "    # Hard events\n",
    "    hard_events = len(ego_df[abs(ego_df['acceleration']) > 3])\n",
    "    if hard_events > 0:\n",
    "        print(f\"⚠️  Hard acceleration/braking: {hard_events} events\")\n",
    "    else:\n",
    "        print(f\"✅ Smooth driving behavior\")\n",
    "    \n",
    "    print(f\"\\nOverall Safety Rating: {safety_rating}\")\n",
    "    \n",
    "    # Performance summary\n",
    "    if performance_metrics:\n",
    "        print(f\"\\n🏎️ PERFORMANCE SUMMARY\")\n",
    "        print(f\"-\" * 22)\n",
    "        print(f\"Speed tracking error: {performance_metrics['avg_speed_error']:.2f} m/s\")\n",
    "        print(f\"Smoothness (avg jerk): {performance_metrics['avg_jerk']:.2f} m/s³\")\n",
    "        print(f\"Energy consumption: {performance_metrics['total_energy']:.1f} units\")\n",
    "        print(f\"Overall performance: {performance_metrics['performance_score']:.1f}/100\")\n",
    "        \n",
    "        if performance_metrics['performance_score'] >= 80:\n",
    "            perf_grade = \"Excellent ⭐⭐⭐⭐⭐\"\n",
    "        elif performance_metrics['performance_score'] >= 70:\n",
    "            perf_grade = \"Good ⭐⭐⭐⭐\"\n",
    "        elif performance_metrics['performance_score'] >= 60:\n",
    "            perf_grade = \"Fair ⭐⭐⭐\"\n",
    "        else:\n",
    "            perf_grade = \"Needs Improvement ⭐⭐\"\n",
    "        \n",
    "        print(f\"Performance Grade: {perf_grade}\")\n",
    "    \n",
    "    # Behavioral insights\n",
    "    if ml_results:\n",
    "        print(f\"\\n🧠 BEHAVIORAL INSIGHTS\")\n",
    "        print(f\"-\" * 22)\n",
    "        print(f\"Behavioral patterns identified: {ml_results['optimal_k']}\")\n",
    "        print(f\"Pattern separation quality: {ml_results['silhouette_score']:.3f}\")\n",
    "        \n",
    "        # Dominant behavior\n",
    "        dominant_cluster = pd.Series(ml_results['clusters']).value_counts().index[0]\n",
    "        dominant_pct = pd.Series(ml_results['clusters']).value_counts().iloc[0] / len(ml_results['clusters']) * 100\n",
    "        print(f\"Dominant behavior: Pattern {dominant_cluster} ({dominant_pct:.1f}% of time)\")\n",
    "    \n",
    "    # Key findings\n",
    "    print(f\"\\n🔍 KEY FINDINGS\")\n",
    "    print(f\"-\" * 15)\n",
    "    \n",
    "    findings = []\n",
    "    \n",
    "    # Speed analysis\n",
    "    avg_speed = ego_df['speed'].mean()\n",
    "    speed_std = ego_df['speed'].std()\n",
    "    \n",
    "    if speed_std < 2:\n",
    "        findings.append(\"✅ Consistent speed control\")\n",
    "    else:\n",
    "        findings.append(\"⚠️  Variable speed control - consider optimization\")\n",
    "    \n",
    "    if avg_speed > 28:\n",
    "        findings.append(\"⚠️  Tends to drive above recommended speeds\")\n",
    "    elif avg_speed < 20:\n",
    "        findings.append(\"ℹ️  Conservative driving speeds\")\n",
    "    else:\n",
    "        findings.append(\"✅ Appropriate average speed\")\n",
    "    \n",
    "    # Acceleration analysis\n",
    "    avg_abs_accel = abs(ego_df['acceleration']).mean()\n",
    "    if avg_abs_accel < 1:\n",
    "        findings.append(\"✅ Smooth acceleration patterns\")\n",
    "    else:\n",
    "        findings.append(\"⚠️  Frequent acceleration changes\")\n",
    "    \n",
    "    # Lane change analysis\n",
    "    if 'lane_change' in ego_df.columns:\n",
    "        lane_changes = ego_df['lane_change'].sum()\n",
    "        if lane_changes == 0:\n",
    "            findings.append(\"ℹ️  No lane changes performed\")\n",
    "        elif lane_changes < 3:\n",
    "            findings.append(\"✅ Conservative lane changing\")\n",
    "        else:\n",
    "            findings.append(\"ℹ️  Active lane changing behavior\")\n",
    "    \n",
    "    for finding in findings:\n",
    "        print(f\"  {finding}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n💡 RECOMMENDATIONS\")\n",
    "    print(f\"-\" * 18)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    if performance_metrics and performance_metrics['avg_speed_error'] > 2:\n",
    "        recommendations.append(\"🎯 Improve speed tracking with better control algorithms\")\n",
    "    \n",
    "    if performance_metrics and performance_metrics['avg_jerk'] > 2:\n",
    "        recommendations.append(\"🌊 Implement smoother acceleration profiles\")\n",
    "    \n",
    "    if collision_df.empty:\n",
    "        recommendations.append(\"✅ Maintain current safety protocols\")\n",
    "    else:\n",
    "        recommendations.append(\"🚨 Review and enhance collision avoidance systems\")\n",
    "    \n",
    "    if speed_violations > 0:\n",
    "        recommendations.append(\"📏 Implement stricter speed limit compliance\")\n",
    "    \n",
    "    if ml_results and ml_results['silhouette_score'] < 0.3:\n",
    "        recommendations.append(\"🔄 Consider behavior consistency improvements\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"🎉 Performance is excellent - continue current approach\")\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(f\"\\n🏆 OVERALL ASSESSMENT\")\n",
    "    print(f\"-\" * 22)\n",
    "    \n",
    "    safety_score = 100 if collision_df.empty else max(0, 100 - len(collision_df) * 20)\n",
    "    perf_score = performance_metrics['performance_score'] if performance_metrics else 75\n",
    "    behavior_score = ml_results['silhouette_score'] * 100 if ml_results else 75\n",
    "    \n",
    "    overall_score = (safety_score + perf_score + behavior_score) / 3\n",
    "    \n",
    "    print(f\"Safety Score: {safety_score:.0f}/100\")\n",
    "    print(f\"Performance Score: {perf_score:.0f}/100\")\n",
    "    print(f\"Behavior Score: {behavior_score:.0f}/100\")\n",
    "    print(f\"\\n🎯 OVERALL SCORE: {overall_score:.0f}/100\")\n",
    "    \n",
    "    if overall_score >= 90:\n",
    "        grade = \"A+ (Exceptional) 🏆\"\n",
    "    elif overall_score >= 80:\n",
    "        grade = \"A (Excellent) ⭐\"\n",
    "    elif overall_score >= 70:\n",
    "        grade = \"B (Good) 👍\"\n",
    "    elif overall_score >= 60:\n",
    "        grade = \"C (Satisfactory) 📈\"\n",
    "    else:\n",
    "        grade = \"D (Needs Improvement) 🔧\"\n",
    "    \n",
    "    print(f\"Grade: {grade}\")\n",
    "    \n",
    "    return {\n",
    "        'safety_rating': safety_rating,\n",
    "        'overall_score': overall_score,\n",
    "        'grade': grade,\n",
    "        'key_findings': findings,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "# Generate comprehensive summary\n",
    "summary_results = generate_analysis_summary(analysis_data, performance_metrics, ml_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_results_header"
   },
   "source": [
    "## 💾 Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_results"
   },
   "outputs": [],
   "source": [
    "# Export analysis results to files\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_analysis_results(analysis_data, performance_metrics, ml_results, summary_results):\n",
    "    \"\"\"Export all analysis results to files\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create analysis summary report\n",
    "    report = {\n",
    "        'timestamp': timestamp,\n",
    "        'data_summary': {\n",
    "            'total_records': len(analysis_data['all_vehicles']) if analysis_data else 0,\n",
    "            'ego_records': len(analysis_data['ego_vehicles']) if analysis_data else 0,\n",
    "            'collision_events': len(analysis_data['collisions']) if analysis_data else 0,\n",
    "            'action_events': len(analysis_data['actions']) if analysis_data else 0\n",
    "        },\n",
    "        'performance_metrics': performance_metrics,\n",
    "        'ml_analysis': {\n",
    "            'optimal_clusters': ml_results['optimal_k'] if ml_results else None,\n",
    "            'silhouette_score': ml_results['silhouette_score'] if ml_results else None\n",
    "        },\n",
    "        'summary': summary_results\n",
    "    }\n",
    "    \n",
    "    # Save as JSON\n",
    "    report_filename = f\"analysis_report_{timestamp}.json\"\n",
    "    with open(report_filename, 'w') as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"📄 Analysis report saved: {report_filename}\")\n",
    "    \n",
    "    # Create detailed CSV exports\n",
    "    if analysis_data and not analysis_data['ego_vehicles'].empty:\n",
    "        # Enhanced ego vehicle data with analysis features\n",
    "        ego_enhanced = analysis_data['ego_vehicles'].copy()\n",
    "        \n",
    "        if ml_results:\n",
    "            ego_enhanced['behavioral_cluster'] = ml_results['clusters']\n",
    "        \n",
    "        if performance_metrics:\n",
    "            # Add performance scores (simplified)\n",
    "            target_speed = 25.0\n",
    "            ego_enhanced['speed_error'] = abs(ego_enhanced['speed'] - target_speed)\n",
    "            ego_enhanced['energy_consumption'] = abs(ego_enhanced['acceleration']) ** 2 * 0.1\n",
    "        \n",
    "        enhanced_filename = f\"enhanced_analysis_{timestamp}.csv\"\n",
    "        ego_enhanced.to_csv(enhanced_filename, index=False)\n",
    "        print(f\"📊 Enhanced data saved: {enhanced_filename}\")\n",
    "    \n",
    "    return report_filename\n",
    "\n",
    "# Export results\n",
    "if analysis_data:\n",
    "    report_file = export_analysis_results(analysis_data, performance_metrics, ml_results, summary_results)\n",
    "    print(f\"\\n✅ Analysis complete! Results exported to {report_file}\")\nelse:\n",
    "    print(\"❌ No data available for export\")\n",
    "\n",
    "# Download files if in Colab\n",
    "if IN_COLAB and 'report_file' in locals():\n",
    "    print(\"\\n📥 Downloading analysis files...\")\n",
    "    try:\n",
    "        files.download(report_file)\n",
    "        \n",
    "        # Download enhanced data if it exists\n",
    "        enhanced_files = [f for f in os.listdir('.') if f.startswith('enhanced_analysis_')]\n",
    "        for file in enhanced_files:\n",
    "            files.download(file)\n",
    "        \n",
    "        print(\"📥 Download complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion_header"
   },
   "source": [
    "## 🎉 Analysis Complete!\n",
    "\n",
    "### 📊 What You've Accomplished:\n",
    "✅ **Comprehensive Data Analysis** - Statistical summaries and key metrics  \n",
    "✅ **Vehicle Trajectory Analysis** - Path efficiency and movement patterns  \n",
    "✅ **Safety Assessment** - Risk analysis and collision evaluation  \n",
    "✅ **Autonomous Behavior Analysis** - Decision-making pattern identification  \n",
    "✅ **Performance Optimization** - Efficiency metrics and improvement opportunities  \n",
    "✅ **Machine Learning Insights** - Behavioral clustering and pattern recognition  \n",
    "✅ **Actionable Recommendations** - Specific improvement suggestions  \n",
    "\n",
    "### 🔍 Key Insights Generated:\n",
    "- **Safety Metrics** - Collision analysis and risk assessment\n",
    "- **Performance Scores** - Speed tracking, smoothness, and energy efficiency\n",
    "- **Behavioral Patterns** - ML-identified driving styles and transitions\n",
    "- **Optimization Opportunities** - Specific areas for algorithm improvement\n",
    "- **Comparative Analysis** - Benchmarking against ideal performance\n",
    "\n",
    "### 📈 Research Applications:\n",
    "- **Algorithm Development** - Data-driven improvements to AV systems\n",
    "- **Safety Validation** - Evidence-based safety assessment\n",
    "- **Performance Benchmarking** - Quantitative comparison metrics\n",
    "- **Behavioral Modeling** - Understanding autonomous decision patterns\n",
    "- **Predictive Analytics** - Identifying potential failure modes\n",
    "\n",
    "### 🔗 Next Steps:\n",
    "1. **[04_visualization_examples.ipynb](04_visualization_examples.ipynb)** - Create publication-ready plots\n",
    "2. **[05_advanced_analysis.ipynb](05_advanced_analysis.ipynb)** - Advanced statistical modeling\n",
    "3. **Implement Recommendations** - Apply insights to improve the simulation\n",
    "4. **Comparative Studies** - Run A/B tests with different configurations\n",
    "\n",
    "### 💡 Pro Tips for Further Analysis:\n",
    "- **Experiment with different environments** to compare performance\n",
    "- **Vary simulation parameters** to test robustness\n",
    "- **Implement suggested optimizations** and re-analyze\n",
    "- **Use ML insights** to develop predictive models\n",
    "- **Create custom metrics** for specific research questions\n",
    "\n",
    "---\n",
    "\n",
    "**Your AV simulation data has been thoroughly analyzed! 🚗📊**\n",
    "\n",
    "**Ready for visualization and advanced modeling!** 📈🤖"
   ]
  }
 ],\n "metadata": {\n  "colab": {\n   "provenance": [],\n   "toc_visible": true\n  },\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.10"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}