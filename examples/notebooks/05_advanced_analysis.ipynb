{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# \ud83d\udd2c Advanced AV Simulation Analysis\n",
        "\n",
        "Advanced analytics and machine learning on simulation data.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aanshshah/av-simulation/blob/main/examples/notebooks/05_advanced_analysis.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## Setup Analysis Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "\n",
        "base_path = '/content' if ('/content' in os.getcwd() or 'COLAB_GPU' in os.environ) else os.getcwd()\n",
        "repo_path = os.path.join(base_path, 'av-simulation')\n",
        "sim_path = os.path.join(repo_path, 'src')\n",
        "\n",
        "for path_entry in (repo_path, sim_path):\n",
        "    if os.path.exists(path_entry) and path_entry not in sys.path:\n",
        "        sys.path.insert(0, path_entry)\n",
        "\n",
        "try:\n",
        "    from av_simulation.data.repository import DataRepository, SimulationData\n",
        "    print('\u2705 Data modules imported successfully')\n",
        "except ImportError as e:\n",
        "    print(f'\u26a0\ufe0f Cannot import data modules: {e}')\n",
        "    print('\ud83d\udca1 Make sure to run 01_colab_setup.ipynb first')\n",
        "\n",
        "sample_candidates = [\n",
        "    os.path.join(repo_path, 'examples', 'notebooks', 'data', 'sample_ego_run.csv'),\n",
        "    os.path.join(base_path, 'examples', 'notebooks', 'data', 'sample_ego_run.csv'),\n",
        "    'examples/notebooks/data/sample_ego_run.csv'\n",
        "]\n",
        "sample_path = next((p for p in sample_candidates if os.path.exists(p)), None)\n",
        "\n",
        "if sample_path:\n",
        "    analysis_base_df = pd.read_csv(sample_path)\n",
        "    print(f'\u2705 Loaded base dataset from {sample_path}')\n",
        "else:\n",
        "    print('\u26a0\ufe0f Sample data not found; generating synthetic dataset for demonstrations')\n",
        "    t = np.linspace(0, 10, 300)\n",
        "    analysis_base_df = pd.DataFrame({\n",
        "        'timestamp': t,\n",
        "        'speed': 20 + 5 * np.sin(t) + np.random.normal(0, 1.5, len(t)),\n",
        "        'acceleration': np.gradient(20 + 5 * np.sin(t), t),\n",
        "        'pos_x': np.linspace(0, 150, len(t)),\n",
        "        'pos_y': 4 * np.sin(t / 2)\n",
        "    })\n",
        "\n",
        "globals()['analysis_base_df'] = analysis_base_df\n",
        "print('\u2705 Advanced analysis libraries loaded')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Time Series Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform time series analysis\n",
        "def analyze_time_series(data):\n",
        "    \"\"\"Analyze time series patterns in simulation data.\"\"\"\n",
        "    results = {\n",
        "        'mean': np.mean(data),\n",
        "        'std': np.std(data),\n",
        "        'trend': stats.linregress(range(len(data)), data).slope\n",
        "    }\n",
        "    return results\n",
        "\n",
        "base_df = globals().get('analysis_base_df')\n",
        "if base_df is not None and 'speed' in base_df:\n",
        "    analysis = analyze_time_series(base_df['speed'])\n",
        "    print(f'Analysis results: {analysis}')\n",
        "else:\n",
        "    print('\u274c No base dataset available for analysis')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply clustering to simulation data\n",
        "def cluster_behaviors(features, n_clusters=3):\n",
        "    \"\"\"Cluster vehicle behaviors.\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    clusters = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "    return clusters, kmeans\n",
        "\n",
        "base_df = globals().get('analysis_base_df')\n",
        "if base_df is not None and {'speed', 'acceleration'} <= set(base_df.columns):\n",
        "    feature_matrix = base_df[['speed', 'acceleration']].to_numpy()\n",
        "    clusters, model = cluster_behaviors(feature_matrix, n_clusters=3)\n",
        "    base_df = base_df.assign(cluster=clusters)\n",
        "    print('\ud83e\udd16 Clustering complete. Cluster counts:')\n",
        "    print(base_df['cluster'].value_counts())\n",
        "else:\n",
        "    print('\u274c Insufficient data for clustering')\n",
        "\n",
        "globals()['analysis_base_df'] = base_df\n",
        "print('\ud83e\udd16 ML functions ready')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}